{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, KFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import  roc_auc_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzy = pd.read_csv('Train.csv')\n",
    "#train, test = train_test_split(enzy, test_size = 0.2, random_state = 101)\n",
    "train = enzy.sample(400000)\n",
    "trainX = train.drop('LABEL', axis=1)\n",
    "trainy = train['LABEL']\n",
    "\n",
    "# testX = test.drop('LABEL', axis=1)\n",
    "# testy = test['LABEL']"
   ]
  },
  {
   "source": [
    "enztest = pd.read_csv('test.csv')\n",
    "enzytest = enztest.copy()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract(f):    \n",
    "    for p in ['A','R','N','D','B','C','Q','E','Z','G','H','I','L','K','M','F','P','S','T','W','Y','V']:\n",
    "        def counter(sequence, let):\n",
    "            return sequence.count(let)\n",
    "        f[p]= f.apply(lambda x: counter(x.SEQUENCE, p), axis =1)\n",
    "    f['Length'] = f.apply(lambda x: len(x.SEQUENCE), axis =1)\n",
    "    f['other'] = f['Length'] - (f['A']+f['R']+f['N']+f['D']+f['B']+f['C']+f['Q']+f['E']+f['Z']+f['G']+f['H']+f['I']+f['L']+f['K']+f['M']+f['F']+f['P']+f['S']+f['T']+f['W']+f['Y']+f['V'])\n",
    "    f.drop(['SEQUENCE','SEQUENCE_ID'], axis=1, inplace = True)\n",
    "\n",
    "Extract(trainX)\n",
    "#Extract(testX)\n",
    "Extract(enzytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt = Pipeline([('Encode', ce.BinaryEncoder(cols= 'CREATURE')),('Sc',RobustScaler())])\n",
    "# trainX= mt.fit_transform(trainX)\n",
    "# #testX= mt.transform(testX)\n",
    "# enzytest= mt.transform(enzytest)"
   ]
  },
  {
   "source": [
    "final = Pipeline([\n",
    "('Encode', ce.BinaryEncoder(cols= 'CREATURE')),\n",
    "('Standization', RobustScaler()),\n",
    "('Ensemble' , VotingClassifier([('rfc', RandomForestClassifier(max_depth=100, max_features='sqrt', min_samples_leaf=2, min_samples_split=10, n_estimators=500)), \n",
    "                                ('knc', KNeighborsClassifier(algorithm = 'ball_tree', leaf_size = 13, n_neighbors = 18, weights = 'distance'))])\n",
    ")])\n",
    "\n",
    "final.fit(trainX, trainy)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Encode', BinaryEncoder(cols='CREATURE')),\n",
       "                ('Standization', RobustScaler()),\n",
       "                ('Ensemble',\n",
       "                 VotingClassifier(estimators=[('rfc',\n",
       "                                               RandomForestClassifier(max_depth=100,\n",
       "                                                                      max_features='sqrt',\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=10,\n",
       "                                                                      n_estimators=500)),\n",
       "                                              ('knc',\n",
       "                                               KNeighborsClassifier(algorithm='ball_tree',\n",
       "                                                                    leaf_size=13,\n",
       "                                                                    n_neighbors=18,\n",
       "                                                                    weights='distance'))]))])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "source": [
    "pred = final.predict(enzytest)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = pd.DataFrame(enztest['SEQUENCE_ID'])\n",
    "two = pd.DataFrame(pred)\n",
    "Done = pd.concat([one,two], axis=1)\n",
    "Done.columns = ['SEQUENCE_ID','LABEL']\n",
    "Done.to_csv('Enzyme-Solution.csv',index=False)"
   ]
  },
  {
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#def model():\n",
    "md = Sequential()\n",
    "md.add(Dense(32, activation= 'relu', input_dim = trainX.shape[1]))\n",
    "md.add(Dense(units = 32, activation= 'relu'))\n",
    "md.add(Dense(units = 32, activation= 'relu'))\n",
    "md.add(Dense(units = 32, activation= 'softmax'))\n",
    "md.add(Dense(units = 20,))\n",
    "\n",
    "md.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "md.fit(trainX, trainy, batch_size=trainX.shape[1], epochs=50, verbose=0)\n",
    "#return md\n",
    "    \n",
    "# estimator = KerasClassifier(build_fn=model, epochs=200, batch_size=5, verbose=0)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(estimator, trainX, trainy, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "ypred = md.predict(testX)\n",
    "print(roc_auc_score(testy, ypred))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class DropFeatures(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # Drop irrelevant features\n",
    "        X.drop(self.attribute_names, axis=1, inplace=True)\n",
    "        return X"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": []
  },
  {
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class Extract(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        for p in ['A','R','N','D','B','C','Q','E','Z','G','H','I','L','K','M','F','P','S','T','W','Y','V']:\n",
    "            def counter(sequence, let):\n",
    "                return sequence.count(let)\n",
    "            X[p]= X.apply(lambda self: counter(self.SEQUENCE, p), axis =1)\n",
    "        X['Length'] = X.apply(lambda self: len(self.SEQUENCE), axis =1)\n",
    "        X['other'] = X['Length'] - (X['A']+X['R']+X['N']+X['D']+X['B']+X['C']+X['Q']+X['E']+X['Z']+X['G']+X['H']+X['I']+X['L']+X['K']+X['M']+X['X']+X['P']+X['S']+X['T']+X['W']+X['Y']+X['V'])\n",
    "        X.drop(self.attribute_names, axis=1, inplace=True)\n",
    "        return X\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "source": [
    "enzy = pd.read_csv('Train.csv', chunksize =100000, iterator=True)\n",
    "\n",
    "for enz in enzy:\n",
    "    def Extract(f):    \n",
    "        for p in ['A','R','N','D','B','C','Q','E','Z','G','H','I','L','K','M','F','P','S','T','W','Y','V']:\n",
    "            def counter(sequence, let):\n",
    "                return sequence.count(let)\n",
    "            f[p]= f.apply(lambda x: counter(x.SEQUENCE, p), axis =1)\n",
    "        f['Length'] = f.apply(lambda x: len(x.SEQUENCE), axis =1)\n",
    "        f['other'] = f['Length'] - (f['A']+f['R']+f['N']+f['D']+f['B']+f['C']+f['Q']+f['E']+f['Z']+f['G']+f['H']+f['I']+f['L']+f['K']+f['M']+f['F']+f['P']+f['S']+f['T']+f['W']+f['Y']+f['V'])\n",
    "        f.drop(['SEQUENCE','SEQUENCE_ID'], axis=1, inplace = True)\n",
    "\n",
    "    Extract(enz)\n",
    "\n",
    "    X = enz.drop('LABEL', axis=1)\n",
    "    y = enz['LABEL']\n",
    "\n",
    "    Encode = ce.BinaryEncoder(cols= 'CREATURE')\n",
    "    X = Encode.fit_transform(X,)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "\n",
    "    # Finding the BaseLine perfomance of the various models\n",
    "    # prepare models\n",
    "    models = []\n",
    "\n",
    "    # Adding algorthms\n",
    "    #models.append(('sgd', SGDClassifier()))\n",
    "    models.append(('knc', KNeighborsClassifier()))\n",
    "    models.append(('rfc', RandomForestClassifier()))\n",
    "    #models.append(('xg', XGBClassifier()))\n",
    "    #models.append(('svc', SVC()))\n",
    "    #models.append(('mlp', MLPClassifier()))\n",
    "\n",
    "    # evaluate -cross validation- each model in turn\n",
    "    results = []\n",
    "    names = []\n",
    "    #scoring = ['f1_weighted', 'roc_auc_ovo_weighted']\n",
    "    scoring = 'f1_weighted'\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=7, random_state=7)\n",
    "        #cv_results = cross_validate(model, X, y, cv=kfold, scoring=scoring, n_jobs=-1, return_train_score=True)\n",
    "        cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring, n_jobs=-1)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f\" % (name, cv_results.mean())\n",
    "        print(msg)\n",
    "        #msg = \"%s: %f (%f)\" % (name, cv_results['train_f1_weighted'].mean(), cv_results['test_roc_auc_ovo_weighted'].mean())\n",
    "results.append(results.mean())\n",
    "names.append(name)\n",
    "msg = \"%s: %f\" % (name, results.mean())\n",
    "print(msg)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "knc: 0.805325\n",
      "rfc: 0.816907\n",
      "knc: 0.802734\n",
      "rfc: 0.816063\n",
      "knc: 0.801359\n",
      "rfc: 0.811419\n",
      "knc: 0.804776\n",
      "rfc: 0.814156\n",
      "knc: 0.802506\n",
      "rfc: 0.813193\n",
      "knc: 0.805005\n",
      "rfc: 0.815938\n",
      "knc: 0.802699\n",
      "rfc: 0.812626\n",
      "knc: 0.801287\n",
      "rfc: 0.812729\n",
      "knc: 0.758673\n",
      "rfc: 0.789016\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9a1b4f7c0648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m#msg = \"%s: %f (%f)\" % (name, cv_results['train_f1_weighted'].mean(), cv_results['test_roc_auc_ovo_weighted'].mean())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "    # importing libraries for bayesian optimization on Random Forest\n",
    "    from skopt import BayesSearchCV\n",
    "    from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "    search_space = {'max_depth': Integer(10, 100), 'n_estimators':Integer(200,500), \"max_features\": Categorical(['auto', 'sqrt','log2']), \"min_samples_leaf\": Integer(2, 10), \"min_samples_split\": Integer(2, 10)}\n",
    "\n",
    "    rfr_bayes = BayesSearchCV(RandomForestClassifier(), search_space, n_iter=32, scoring='f1_weighted', n_jobs=-1, cv =5)\n",
    "    rfr_bayes.fit(X, y)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=32, n_jobs=-1,\n",
       "              scoring='f1_weighted',\n",
       "              search_spaces={'max_depth': Integer(low=10, high=100, prior='uniform', transform='identity'),\n",
       "                             'max_features': Categorical(categories=('auto', 'sqrt', 'log2'), prior=None),\n",
       "                             'min_samples_leaf': Integer(low=2, high=10, prior='uniform', transform='identity'),\n",
       "                             'min_samples_split': Integer(low=2, high=10, prior='uniform', transform='identity'),\n",
       "                             'n_estimators': Integer(low=200, high=500, prior='uniform', transform='identity')})"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "source": [
    "# importing libraries for bayesian optimization on KNN\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "search_space = {'n_neighbors': Integer(1,200), 'weights': Categorical(['uniform', 'distance']), \"algorithm\": Categorical(['auto', 'ball_tree', 'kd_tree', 'brute']), \"leaf_size\": Integer(2, 200)}\n",
    " \n",
    "kn_bayes = BayesSearchCV(KNeighborsClassifier(), search_space, n_iter=32, scoring='f1_weighted', n_jobs=-1, cv =5)\n",
    "kn_bayes.fit(X, y)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.00 GiB for an array with shape (2854, 47022) and data type float64",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 560, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 607, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in __call__\n    sample_weight=sample_weight)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 206, in _score\n    y_pred = method_caller(estimator, \"predict\", X)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 53, in _cached_call\n    return getattr(estimator, method)(*args, **kwargs)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 175, in predict\n    neigh_dist, neigh_ind = self.kneighbors(X)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 644, in kneighbors\n    **kwds))\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1617, in pairwise_distances_chunked\n    n_jobs=n_jobs, **kwds)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1779, in pairwise_distances\n    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1360, in _parallel_pairwise\n    return func(X, Y, **kwds)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\iDAFAdmin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 310, in euclidean_distances\n    distances = - 2 * safe_sparse_dot(X, Y.T, dense_output=True)\nMemoryError: Unable to allocate 1.00 GiB for an array with shape (2854, 47022) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-711cdea0bd36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mkn_bayes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_weighted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mkn_bayes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[0;32m    692\u001b[0m                 optim_result = self._step(\n\u001b[0;32m    693\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m                     \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m                 )\n\u001b[0;32m    696\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[0;32m    421\u001b[0m                 \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m             )\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m             for train, test in cv_iter)\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.00 GiB for an array with shape (2854, 47022) and data type float64"
     ]
    }
   ]
  },
  {
   "source": [
    "vt = VotingClassifier([('rfc',rfr_bayes.best_estimator_), ('knc', kn_bayes.best_estimator_)])\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "#cv_results = cross_validate(model, X, y, cv=kfold, scoring=scoring, n_jobs=-1, return_train_score=True)\n",
    "cv_results = cross_val_score(vt, X, y, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "#msg = \"%s: %f (%f)\" % (name, cv_results['train_f1_weighted'].mean(), cv_results['test_roc_auc_ovo_weighted'].mean())\n",
    "msg = \"%s: %f\" % ('vt', cv_results.mean())\n",
    "print(msg)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}